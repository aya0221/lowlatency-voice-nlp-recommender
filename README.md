# Voice-Driven AI Workout Assistant

A fully production-ready, voice-activated assistant that transcribes spoken commands, classifies user intent, extracts workout-specific entities, and retrieves tailored workout recommendations from OpenSearch.

---

## ğŸš€ Features

- **ğŸ™ï¸ Real-Time ASR (Speech-to-Text)**  
  Transcribes live voice commands using OpenAI Whisper for fast and robust audio understanding.

- **ğŸ§  Intent Classification (Fine-tuned DistilBERT)**  
  Intent Classification (Fine-tuned DistilBERT): Extracts user intent (e.g., search class, track progress) from spoken text using a DistilBERT model I fine-tuned on task-specific examples. Trained on custom-labeled data with GPU acceleration and hyperparameter optimization to maximize accuracy and confidence.

- **ğŸ” Named Entity Recognition (NER)**  
  Hybrid spaCy pipeline combining ML-based NER with custom rule-based matchers to extract structured entities like duration, intensity, instructor, workout type, and goals.

- **âš¡ Semantic Search & Recommendations (OpenSearch)**  
  Vectorized search across structured workout data using boosted relevance scoring. Returns personalized workout matches based on user input semantics.

- **ğŸ§© Modular, Extensible Architecture**  
  Clean, well-documented Python modules with separation of concerns across ASR, NLU, and search layers â€” ready for scaling, fine-tuning, or API integration.

---

## ğŸ§  Pipeline Overview

```bash
Voice Input â†’ Whisper (ASR) â†’ Intent Classifier â†’ NER â†’ OpenSearch Query â†’ Workout Results
```

---

## ğŸ” End-to-End Pipeline Demo

The following screenshot shows the full real-time pipeline in action:

1. Whisper-based voice transcription  
2. Intent detection via fine-tuned DistilBERT  
3. Entity recognition using spaCy + keyword matcher  
4. Relevance-ranked search with OpenSearch  
5. Top 10 personalized workout recommendations  

![Demo Output](./assets/demo_pipeline_output.png)


## ğŸ”§ Technologies & Tools

- **Python 3.11**
- **PyTorch / HuggingFace Transformers** (intent classification)
- **spaCy** (NER with custom patterns)
- **OpenAI Whisper** (ASR)
- **OpenSearch** (indexed retrieval)
- **Docker + Docker Compose** (local OpenSearch cluster)
- **MLflow** *(optional)*: for model tracking
- **Airflow** *(optional)*: for orchestration

---

## ğŸ“ Project Structure

```bash
voice_assistant/
â”œâ”€â”€ asr/                  # Whisper-based ASR
â”‚   â””â”€â”€ transcribe.py     # Transcribes audio into text
â”‚   â””â”€â”€ record_and_transcribe.py     # Records audio and transcribes
â”œâ”€â”€ data/                 # Input audio + training CSVs
â”œâ”€â”€ models/               # Fine-tuned intent classifier
â”œâ”€â”€ nlu/                  # Intent & entity extraction logic
â”‚   â”œâ”€â”€ custom_entity_extractor.py
â”‚   â”œâ”€â”€ train_intent_classifier.py
â”‚   â””â”€â”€ nlu_pipeline.py   # End-to-end NLP pipeline
â”œâ”€â”€ search/               # OpenSearch indexing + query
â”œâ”€â”€ utils/                # Configs and shared helpers
â””â”€â”€ app.py                # (Optional) CLI or UI runner
```

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/aya0221/voice-ai-workout-assistant.git
cd voice-ai-workout-assistant
python -m venv venv-voice-ai-coach
source venv-voice-ai-coach/bin/activate
pip install -r requirements.txt
```

---

## ğŸ—£ï¸ Run the Assistant (End-to-End)

```bash
# Run the full voice-driven NLP pipeline:
python voice_assistant/nlu/nlu_pipeline.py
```

This will:

- Record 5 seconds of speech via microphone
- Transcribe the `.wav` using Whisper ASR
- Classify the intent (fine-tuned DistilBERT)
- Extract structured entities (via spaCy + rule-based matcher)
- Query OpenSearch index and return top matching workouts

---

## ğŸ“Š Intent Classes

- `search_class`
- `track_metric`
- `greeting`

All fine-tuned from `distilbert-base-uncased` on 1000+ balanced training examples.

---

## ğŸ§  Entity Types Extracted

| Entity       | Example                |
|--------------|-------------------------|
| `time`       | "30 minute"            |
| `intensity`  | "low impact"          |
| `person`     | "Robin"               |
| `goal`       | "lose weight"         |
| `type`       | "cycling", "yoga"    |
| `tag`        | "endurance", "mood"  |

---

## ğŸ§ª Model Training

Run intent classifier fine-tuning:
```bash
python voice_assistant/nlu/train_intent_classifier.py
```

MLflow or custom logs can be integrated for reproducibility.

---

## ğŸ” Indexing Workouts (OpenSearch)

```bash
# Start OpenSearch cluster
sudo docker-compose up -d

# Index data
python voice_assistant/search/index_workouts.py
```

---

## ğŸ§¼ Best Practices

- âœ… Modular, reusable components
- âœ… Clear logging for demo/debug
- âœ… Scalable for future domain extensions
- âœ… Easy to plug into any UI/frontend

---

## ğŸ§  Future Work

- ğŸ™ï¸ Frontend voice interface (Streamlit or React)
- ğŸ¤– Chatbot-style follow-up for clarification
- ğŸŒ Deployment on HuggingFace Spaces or local Docker API
- ğŸ“ˆ MLflow integration for training runs
- â° Airflow DAG for pipeline automation


---
## ğŸ”Š Test Only ASR (Speech â†’ Text)

```bash
# Record a 5-second voice command
ffmpeg -f alsa -i default -t 5 voice_assistant/data/input.wav

# Run ASR transcription only
python voice_assistant/asr/transcribe.py --file voice_assistant/data/input.wav
```

**Expected Output:**

```
Loading Whisper model...
Transcribing...
Transcription: find me a 30 minute ride with Cody
```

--- 

## ğŸ“¬ Contact
For technical questions, feel free to reach out via the repo's issues tab or email (ayaoshima.us@gmail.com).